{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "Make sure to choose GPU under Edit -> Notebook settings -> Hardware accelerator"
      ],
      "metadata": {
        "id": "uFnJhkkvEqzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "GuEceGiREs7M"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"train_cleaned.csv\")\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "WD5H-mxLEuun",
        "outputId": "7b181d0d-c6c2-4505-a9f5-3a1d815d4547"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id                                       comment_text  toxic  \\\n",
              "0  0000997932d777bf  explanation\\n  edits made   username hardcore ...      0   \n",
              "1  000103f0d9cfb60f  daww  matches  background colour im seemingly ...      0   \n",
              "2  000113f07ec002fd  hey man im really  trying  edit war     guy  c...      0   \n",
              "3  0001b41b1c6bb37e  cant make  real suggestions  improvement   won...      0   \n",
              "4  0001d958c54c6e35           sir   hero  chance  remember  page thats      0   \n",
              "\n",
              "   severe_toxic  obscene  threat  insult  identity_hate  \\\n",
              "0             0        0       0       0              0   \n",
              "1             0        0       0       0              0   \n",
              "2             0        0       0       0              0   \n",
              "3             0        0       0       0              0   \n",
              "4             0        0       0       0              0   \n",
              "\n",
              "                                  comment_text_words  \n",
              "0  ['explanation', 'edits', 'made', 'username', '...  \n",
              "1  ['daww', 'matches', 'background', 'colour', 'i...  \n",
              "2  ['hey', 'man', 'im', 'really', 'trying', 'edit...  \n",
              "3  ['cant', 'make', 'real', 'suggestions', 'impro...  \n",
              "4  ['sir', 'hero', 'chance', 'remember', 'page', ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fb93cbc0-00bd-44c5-84f1-3dc62de1988d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>comment_text_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>explanation\\n  edits made   username hardcore ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['explanation', 'edits', 'made', 'username', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>daww  matches  background colour im seemingly ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['daww', 'matches', 'background', 'colour', 'i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>hey man im really  trying  edit war     guy  c...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['hey', 'man', 'im', 'really', 'trying', 'edit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>cant make  real suggestions  improvement   won...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['cant', 'make', 'real', 'suggestions', 'impro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>sir   hero  chance  remember  page thats</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['sir', 'hero', 'chance', 'remember', 'page', ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb93cbc0-00bd-44c5-84f1-3dc62de1988d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fb93cbc0-00bd-44c5-84f1-3dc62de1988d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fb93cbc0-00bd-44c5-84f1-3dc62de1988d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print((data.toxic == 1).sum()) # toxic\n",
        "print((data.toxic == 0).sum()) # non toxic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSHYN7sjkjCv",
        "outputId": "6b81bd6c-8a81-4152-9c0a-0a96afc9cc54"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13934\n",
            "135414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizing Comments using TextVectorization"
      ],
      "metadata": {
        "id": "6UbCdFCWGywU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find the maximum number of words present in any given comment\n",
        "\n",
        "maxlen = 0\n",
        "longest_comment = \"\"\n",
        "for comment in data['comment_text']:\n",
        "    length = len(comment)\n",
        "    if (length > maxlen):\n",
        "        longest_comment = comment\n",
        "    maxlen = max(maxlen, length)\n",
        "\n",
        "print(\"Number of characters in the longest comment is\", maxlen)\n",
        "print(\"Number of words in the longest comment is\",\n",
        "      len(longest_comment.split(\" \")) + 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Zsx_3NrG0DH",
        "outputId": "f8c72251-3000-41d3-fb91-e4797589522c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of characters in the longest comment is 5000\n",
            "Number of words in the longest comment is 456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
        "\n",
        "    max_tokens=None,\n",
        "\n",
        "    # this is greater than the max words any comment has (774)\n",
        "    # the remaning spots in the output would be padded by 0s\n",
        "    output_sequence_length=800,\n",
        "\n",
        "    # converets to lowercase and skips all the punctuation\n",
        "    standardize=\"lower_and_strip_punctuation\",\n",
        "\n",
        "    # the tokens will be split at whitespaces\n",
        "    split=\"whitespace\",\n",
        "\n",
        "    # each of the tokens is represented as an integer\n",
        "    output_mode=\"int\",\n",
        ")"
      ],
      "metadata": {
        "id": "TkvJHp9MHY-b"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numpyArray = data[data.columns[1]].to_numpy()\n",
        "vectorize_layer.adapt(numpyArray)"
      ],
      "metadata": {
        "id": "mgGVj-cqH5ik"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing\n",
        "vectorize_layer(\"hello, world!\")"
      ],
      "metadata": {
        "id": "nz1C2APzH7Fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1835794a-cdf2-4b98-e0a7-1275e4f38e58"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(800,), dtype=int64, numpy=\n",
              "array([185, 161,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0])>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a Tokenizer"
      ],
      "metadata": {
        "id": "D062HPT2IRrD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gets all the words into one string"
      ],
      "metadata": {
        "id": "8R_7GtnhIXZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates the tokenizer class\n",
        "tokenizer = keras.preprocessing.text.Tokenizer()\n",
        "\n",
        "# Combines all the words into one singular string\n",
        "allWordsString = \" \".join(data.head(50)[\"comment_text\"].tolist())\n",
        "allWordsList = allWordsString.split(r\"\\\\s+\")\n",
        "\n",
        "# Updates the tokenizer with the string of all words\n",
        "tokenizer.fit_on_texts(allWordsList)\n",
        "\n",
        "# Prints word dictionary\n",
        "# print(tokenizer.word_index)\n",
        "\n",
        "# Prints length of word dictionary\n",
        "print(len(tokenizer.word_index))\n",
        "\n",
        "# Converts text to numbers\n",
        "print(tokenizer.texts_to_sequences([\"page\", \"im\", \"use\", \"mussolini\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHZXgzpwIc4s",
        "outputId": "41dd7eb6-b170-4c6a-ed64-8eabdf5211f1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1077\n",
            "[[1], [2], [3], [1077]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Vectorization Layer\n",
        "\n",
        "Reference [here](https://www.tensorflow.org/text/tutorials/text_classification_rnn)"
      ],
      "metadata": {
        "id": "tqfwxXw-I4eC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_ROWS = 10000\n",
        "\n",
        "MAX_LENGTH = None\n",
        "encoder = tf.keras.layers.TextVectorization(\n",
        "    output_sequence_length=MAX_LENGTH)\n",
        "encoder.adapt(data.head(NUM_ROWS)[\"comment_text\"].tolist())\n",
        "\n",
        "vocab = np.array(encoder.get_vocabulary())\n",
        "vocab[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUJdUXAbJM0Y",
        "outputId": "b008ab72-5a1b-4a9d-9d29-9f61dc527ed1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['', '[UNK]', 'article', 'page', 'wikipedia', 'would', 'talk',\n",
              "       'like', 'one', 'please', 'dont', 'see', 'also', 'im', 'know',\n",
              "       'think', 'edit', 'people', 'use', 'articles'], dtype='<U322')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the Encoder"
      ],
      "metadata": {
        "id": "jHwkm0nkKO0G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoder removes punctuation and whitespace and forces lowercase so half the cleaning we did was useless"
      ],
      "metadata": {
        "id": "Ix7s6OAeKTpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "commentsToEncode = data.head(3)[\"comment_text\"]\n",
        "print(commentsToEncode)\n",
        "\n",
        "encodedComments = encoder(commentsToEncode).numpy()\n",
        "print(encodedComments)\n",
        "\n",
        "for comment in encodedComments:\n",
        "    print(\" \".join(vocab[comment]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qnWuRZbKWC2",
        "outputId": "5cedc7b5-df81-4555-bcc5-bc1ba6d22123"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    explanation\\n  edits made   username hardcore ...\n",
            "1    daww  matches  background colour im seemingly ...\n",
            "2    hey man im really  trying  edit war     guy  c...\n",
            "Name: comment_text, dtype: object\n",
            "[[  530    53    41   437  4205 14587   257   208  2022  9650  6733  4903\n",
            "   2845    44  1016 11400  2690     9    10   157   357     6     3    56\n",
            "     13  3853]\n",
            " [35388  2050  1647  6725    13  3256  2365    26     6   977    95     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0]\n",
            " [  387   349    13    49   169    16   218   524  1606   406   367    30\n",
            "    399    53   270     6     3   126   341  2062   506   391     0     0\n",
            "      0     0]]\n",
            "explanation edits made username hardcore metallica fan reverted werent vandalisms closure gas voted new york dolls fac please dont remove template talk page since im retired\n",
            "daww matches background colour im seemingly stuck thanks talk january utc               \n",
            "hey man im really trying edit war guy constantly removing relevant information talking edits instead talk page seems care formatting actual info    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the Model"
      ],
      "metadata": {
        "id": "t4nJsC-RKc44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sets random seed so results are identical every time\n",
        "SEED = 1\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "regularization_layer = tf.keras.layers.Dense(\n",
        "    64, \n",
        "    activation=\"relu\", \n",
        "    #kernel runs before activation, activity runs after\n",
        "    kernel_regularizer=tf.keras.regularizers.l1(0.001),\n",
        "    activity_regularizer=tf.keras.regularizers.l2(0.001)\n",
        ")\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=512,\n",
        "        mask_zero=True\n",
        "    ),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "             optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "His9Gga-KfsB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model"
      ],
      "metadata": {
        "id": "h6ZD_a8rKps5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binaryDf = data.head(NUM_ROWS)[[\"comment_text\", \"toxic\"]]\n",
        "\n",
        "split_cutoff = int(0.8 * NUM_ROWS)\n",
        "training_data = binaryDf.iloc[:split_cutoff]\n",
        "validation_data = binaryDf.iloc[split_cutoff:]\n",
        "\n",
        "training_target = training_data.pop(\"toxic\")\n",
        "validation_target = validation_data.pop(\"toxic\")"
      ],
      "metadata": {
        "id": "aC7Jwwn8Ko9S"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Early Stopping\n",
        "\n",
        "to prevent overfitting during the training process"
      ],
      "metadata": {
        "id": "IE5DnrCYLD6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Early Stopping\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\", patience=2)\n",
        "\n",
        "history = model.fit(training_data, training_target, epochs=10, validation_data=(validation_data, validation_target), callbacks=[callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4Dit8XMLFnG",
        "outputId": "2ea85c7f-de89-444c-fd3a-96bb029b8ba7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/backend.py:5676: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "249/250 [============================>.] - ETA: 0s - loss: 0.4315 - accuracy: 0.8843"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/backend.py:5676: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r250/250 [==============================] - 79s 209ms/step - loss: 0.4309 - accuracy: 0.8842 - val_loss: 0.2524 - val_accuracy: 0.9175\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 37s 149ms/step - loss: 0.1995 - accuracy: 0.9360 - val_loss: 0.1742 - val_accuracy: 0.9365\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 29s 115ms/step - loss: 0.0800 - accuracy: 0.9776 - val_loss: 0.1880 - val_accuracy: 0.9365\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 25s 99ms/step - loss: 0.0251 - accuracy: 0.9936 - val_loss: 0.2284 - val_accuracy: 0.9415\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 21s 85ms/step - loss: 0.0089 - accuracy: 0.9990 - val_loss: 0.2548 - val_accuracy: 0.9460\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 20s 81ms/step - loss: 0.0041 - accuracy: 0.9996 - val_loss: 0.2862 - val_accuracy: 0.9450\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 18s 71ms/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.3151 - val_accuracy: 0.9460\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 18s 72ms/step - loss: 0.0033 - accuracy: 0.9998 - val_loss: 0.3093 - val_accuracy: 0.9445\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 16s 63ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.3469 - val_accuracy: 0.9485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Test Data"
      ],
      "metadata": {
        "id": "UVcGMMkNLhPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv(\"test_cleaned.csv\")\n",
        "test_labels = pd.read_csv(\"test_labels.csv\")\n",
        "\n",
        "test_labels = test_labels.loc[test_labels[\"toxic\"] >= 0]\n",
        "merged_df = test_labels.merge(test_data, left_on=\"id\", right_on=\"id\")"
      ],
      "metadata": {
        "id": "w2uxLN9yLi40"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tests all rows with a value of 0 or 1\n",
        "\n",
        "test_df = merged_df[[\"comment_text\", \"toxic\"]]\n",
        "testTarget = test_df.pop(\"toxic\")\n",
        "model.evaluate(test_df, testTarget)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "az3MdT5uRtxR",
        "outputId": "02d57727-bbfd-4650-8c33-8abac6b5f136"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1824/1824 [==============================] - 33s 18ms/step - loss: 0.5244 - accuracy: 0.9054\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5243768095970154, 0.9053542613983154]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tests only rows with a toxic value of 1\n",
        "\n",
        "test_df = merged_df[[\"comment_text\", \"toxic\"]]\n",
        "newTest_df = test_df.loc[test_df[\"toxic\"] == 1]\n",
        "\n",
        "newTestTarget = newTest_df.pop(\"toxic\")\n",
        "model.evaluate(newTest_df, newTestTarget)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccDvsIBkRtn6",
        "outputId": "45e86f37-327c-442b-f2c1-a0c9b60ae906"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "163/163 [==============================] - 3s 20ms/step - loss: 2.7107 - accuracy: 0.6152\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.710728883743286, 0.6152366399765015]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}