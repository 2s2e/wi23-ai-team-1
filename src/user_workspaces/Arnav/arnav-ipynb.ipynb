{"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"ab65a6a126614c4d8a09c3bb162b3d2e4f4a949753c6f0f735c7c1fe269df83b"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Cleaning","metadata":{"id":"AYVsepnsN7Ys"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport tensorflow as tf\nfrom tensorflow import keras","metadata":{"execution":{"iopub.status.busy":"2023-03-05T01:51:07.726882Z","iopub.execute_input":"2023-03-05T01:51:07.728030Z","iopub.status.idle":"2023-03-05T01:51:07.733330Z","shell.execute_reply.started":"2023-03-05T01:51:07.727990Z","shell.execute_reply":"2023-03-05T01:51:07.732218Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/toxic-message-classifier-dataset/train_cleaned.csv\")\n\ndata.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":250},"id":"T3ng90-PS0JD","outputId":"5bab9c74-8f9f-4c7d-d1b4-e034f7b7b3be","pycharm":{"is_executing":true},"execution":{"iopub.status.busy":"2023-03-05T01:51:09.659366Z","iopub.execute_input":"2023-03-05T01:51:09.659863Z","iopub.status.idle":"2023-03-05T01:51:11.882724Z","shell.execute_reply.started":"2023-03-05T01:51:09.659818Z","shell.execute_reply":"2023-03-05T01:51:11.881648Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                 id                                       comment_text  toxic  \\\n0  0000997932d777bf  explanation\\n  edits made   username hardcore ...      0   \n1  000103f0d9cfb60f  daww  matches  background colour im seemingly ...      0   \n2  000113f07ec002fd  hey man im really  trying  edit war     guy  c...      0   \n3  0001b41b1c6bb37e  cant make  real suggestions  improvement   won...      0   \n4  0001d958c54c6e35           sir   hero  chance  remember  page thats      0   \n\n   severe_toxic  obscene  threat  insult  identity_hate  \\\n0             0        0       0       0              0   \n1             0        0       0       0              0   \n2             0        0       0       0              0   \n3             0        0       0       0              0   \n4             0        0       0       0              0   \n\n                                  comment_text_words  \n0  ['explanation', 'edits', 'made', 'username', '...  \n1  ['daww', 'matches', 'background', 'colour', 'i...  \n2  ['hey', 'man', 'im', 'really', 'trying', 'edit...  \n3  ['cant', 'make', 'real', 'suggestions', 'impro...  \n4  ['sir', 'hero', 'chance', 'remember', 'page', ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n      <th>comment_text_words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>explanation\\n  edits made   username hardcore ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>['explanation', 'edits', 'made', 'username', '...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>daww  matches  background colour im seemingly ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>['daww', 'matches', 'background', 'colour', 'i...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>hey man im really  trying  edit war     guy  c...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>['hey', 'man', 'im', 'really', 'trying', 'edit...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>cant make  real suggestions  improvement   won...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>['cant', 'make', 'real', 'suggestions', 'impro...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>sir   hero  chance  remember  page thats</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>['sir', 'hero', 'chance', 'remember', 'page', ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tokenizing Comments using TextVectorization","metadata":{}},{"cell_type":"code","source":"# finding the maximum number of words present in any given comment\nmaxlen = 0\nlongest_comment = \"\"\nfor comment in data['comment_text']:\n    length = len(comment)\n    if (length > maxlen):\n        longest_comment = comment\n    maxlen = max(maxlen, length)\n\nprint(\"Number of characters in the longest comment is\", maxlen)\nprint(\"Number of words in the longest comment is\",\n      len(longest_comment.split(\" \")) + 1)","metadata":{"execution":{"iopub.status.busy":"2023-03-05T01:51:14.661167Z","iopub.execute_input":"2023-03-05T01:51:14.661541Z","iopub.status.idle":"2023-03-05T01:51:14.763656Z","shell.execute_reply.started":"2023-03-05T01:51:14.661506Z","shell.execute_reply":"2023-03-05T01:51:14.762118Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Number of characters in the longest comment is 5000\nNumber of words in the longest comment is 456\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\n\nvectorize_layer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n\n    max_tokens=None,\n\n    # this is greater than the max words any comment has (774)\n    # the remaning spots in the output would be padded by 0s\n    output_sequence_length=800,\n\n    # converets to lowercase and skips all the punctuation\n    standardize=\"lower_and_strip_punctuation\",\n\n    # the tokens will be split at whitespaces\n    split=\"whitespace\",\n\n    # each of the tokens is represented as an integer\n    output_mode=\"int\",\n)","metadata":{"execution":{"iopub.status.busy":"2023-03-05T01:51:19.683253Z","iopub.execute_input":"2023-03-05T01:51:19.683850Z","iopub.status.idle":"2023-03-05T01:51:19.695093Z","shell.execute_reply.started":"2023-03-05T01:51:19.683811Z","shell.execute_reply":"2023-03-05T01:51:19.693765Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"numpyArray = data[data.columns[1]].to_numpy()\nvectorize_layer.adapt(numpyArray)","metadata":{"execution":{"iopub.status.busy":"2023-03-05T01:51:22.714526Z","iopub.execute_input":"2023-03-05T01:51:22.715521Z","iopub.status.idle":"2023-03-05T01:51:43.471660Z","shell.execute_reply.started":"2023-03-05T01:51:22.715480Z","shell.execute_reply":"2023-03-05T01:51:43.470542Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# testing\nvectorize_layer(\"hello, world!\")","metadata":{"execution":{"iopub.status.busy":"2023-03-05T02:47:19.424017Z","iopub.execute_input":"2023-03-05T02:47:19.424364Z","iopub.status.idle":"2023-03-05T02:47:19.487128Z","shell.execute_reply.started":"2023-03-05T02:47:19.424333Z","shell.execute_reply":"2023-03-05T02:47:19.486011Z"},"trusted":true},"execution_count":65,"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(800,), dtype=int64, numpy=\narray([185, 161,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0])>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Creating a Tokenizer","metadata":{}},{"cell_type":"markdown","source":"### Gets all the words into one string","metadata":{}},{"cell_type":"code","source":"# Creates the tokenizer class\ntokenizer = keras.preprocessing.text.Tokenizer()\n\n# Combines all the words into one singular string\nallWordsString = \" \".join(data.head(50)[\"comment_text\"].tolist())\nallWordsList = allWordsString.split(r\"\\\\s+\")\n\n# Updates the tokenizer with the string of all words\ntokenizer.fit_on_texts(allWordsList)\n\n# Prints word dictionary\n# print(tokenizer.word_index)\n\n# Prints length of word dictionary\nprint(len(tokenizer.word_index))\n\n# Converts text to numbers\nprint(tokenizer.texts_to_sequences([\"page\", \"im\", \"use\", \"mussolini\"]))","metadata":{"execution":{"iopub.status.busy":"2023-03-05T02:47:19.488969Z","iopub.execute_input":"2023-03-05T02:47:19.489392Z","iopub.status.idle":"2023-03-05T02:47:19.500480Z","shell.execute_reply.started":"2023-03-05T02:47:19.489353Z","shell.execute_reply":"2023-03-05T02:47:19.499248Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"1077\n[[1], [2], [3], [1077]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Text Vectorization Layer\n### Following [https://www.tensorflow.org/text/tutorials/text_classification_rnn](http://)","metadata":{}},{"cell_type":"code","source":"NUM_ROWS = 50000\n\nMAX_LENGTH = None\nencoder = tf.keras.layers.TextVectorization(output_sequence_length=MAX_LENGTH)\nencoder.adapt(data.head(NUM_ROWS)[\"comment_text\"].tolist())\n\nvocab = np.array(encoder.get_vocabulary())\nvocab[:20]","metadata":{"execution":{"iopub.status.busy":"2023-03-05T02:47:19.503251Z","iopub.execute_input":"2023-03-05T02:47:19.503529Z","iopub.status.idle":"2023-03-05T02:47:28.578845Z","shell.execute_reply.started":"2023-03-05T02:47:19.503495Z","shell.execute_reply":"2023-03-05T02:47:28.577754Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"array(['', '[UNK]', 'article', 'page', 'wikipedia', 'talk', 'please',\n       'would', 'one', 'like', 'dont', 'see', 'also', 'im', 'think',\n       'know', 'edit', 'articles', 'people', 'use'], dtype='<U4955')"},"metadata":{}}]},{"cell_type":"markdown","source":"### Testing the encoder\n\nEncoder removes punctuation and whitespace and forces lowercase so half the cleaning we did was useless","metadata":{}},{"cell_type":"code","source":"commentsToEncode = data.head(3)[\"comment_text\"]\nprint(commentsToEncode)\n\nencodedComments = encoder(commentsToEncode).numpy()\nprint(encodedComments)\n\nfor comment in encodedComments:\n    print(\" \".join(vocab[comment]))","metadata":{"execution":{"iopub.status.busy":"2023-03-05T02:47:28.580576Z","iopub.execute_input":"2023-03-05T02:47:28.581019Z","iopub.status.idle":"2023-03-05T02:47:28.603781Z","shell.execute_reply.started":"2023-03-05T02:47:28.580978Z","shell.execute_reply":"2023-03-05T02:47:28.602862Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"0    explanation\\n  edits made   username hardcore ...\n1    daww  matches  background colour im seemingly ...\n2    hey man im really  trying  edit war     guy  c...\nName: comment_text, dtype: object\n[[  545    47    46   510  4851 10100   697   212  2036  9481  5882  2142\n   2601    37   996 13902  2466     6    10   144   323     5     3    57\n     13  3502]\n [97471  2159  1329  3969    13  4209  2214    23     5   899    94     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0]\n [  380   317    13    53   147    16   224   504  1980   387   376    27\n    446    47   244     5     3   108   338  2144   540   331     0     0\n      0     0]]\nexplanation edits made username hardcore metallica fan reverted werent vandalisms closure gas voted new york dolls fac please dont remove template talk page since im retired\ndaww matches background colour im seemingly stuck thanks talk january utc               \nhey man im really trying edit war guy constantly removing relevant information talking edits instead talk page seems care formatting actual info    \n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Building the model","metadata":{}},{"cell_type":"code","source":"# Sets random seed so results are identical every time\nSEED = 1\ntf.random.set_seed(SEED)\nnp.random.seed(SEED)\n\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nepochs = 25\nlearning_rate = 0.0001\noptimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\nembedding_size = 512\nlstm_size_1 = 128\nconv_size_2 = 64\n\nmodel = tf.keras.Sequential([\n    encoder,\n    tf.keras.layers.Embedding(\n        input_dim=len(encoder.get_vocabulary()),\n        output_dim=embedding_size,\n        mask_zero=True,\n        embeddings_regularizer=tf.keras.regularizers.L2(0.001)\n    ),\n    tf.keras.layers.Conv1D(128, 5, activation='relu', padding='same'),\n    tf.keras.layers.MaxPooling1D(pool_size=2),\n    tf.keras.layers.Conv1D(conv_size_2, 5, activation='relu', padding='same'),\n    tf.keras.layers.MaxPooling1D(pool_size=2),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_size_1, return_sequences=True)),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.001)),\n    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.001)),\n    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.001)),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizer,\n              metrics=['accuracy'])\n\n# Add early stopping callback to prevent overfitting\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3)\n\nmodel.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n             optimizer=tf.keras.optimizers.Adam(1e-4),\n              metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2023-03-05T02:28:04.069466Z","iopub.execute_input":"2023-03-05T02:28:04.070166Z","iopub.status.idle":"2023-03-05T02:28:08.260677Z","shell.execute_reply.started":"2023-03-05T02:28:04.070126Z","shell.execute_reply":"2023-03-05T02:28:08.259627Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"\n### Training the model","metadata":{}},{"cell_type":"code","source":"binaryDf = data.head(NUM_ROWS)[[\"comment_text\", \"toxic\"]]\n\nsplit_cutoff = int(0.8 * NUM_ROWS)\ntraining_data = binaryDf.iloc[:split_cutoff]\nvalidation_data = binaryDf.iloc[split_cutoff:]\n\ntraining_target = training_data.pop(\"toxic\")\nvalidation_target = validation_data.pop(\"toxic\")","metadata":{"execution":{"iopub.status.busy":"2023-03-05T02:28:18.476261Z","iopub.execute_input":"2023-03-05T02:28:18.476635Z","iopub.status.idle":"2023-03-05T02:28:18.487083Z","shell.execute_reply.started":"2023-03-05T02:28:18.476599Z","shell.execute_reply":"2023-03-05T02:28:18.485840Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"# # training_dataset = tf.convert_to_tensor(training_data)\n# # validation_dataset = tf.convert_to_tensor(validation_data)\n\n# validation_target = validation_data.pop(\"toxic\")\n# validation_dataset = tf.convert_to_tensor(validation_data)\n\n# # history = model.fit(training_dataset, target, epochs=10, validation_data=(validation_dataset, validation_target))\n\n# binaryDf = data.head(NUM_ROWS)[[\"comment_text\", \"toxic\"]]\n# target = binaryDf.pop(\"toxic\")\n# dataset = tf.convert_to_tensor(binaryDf)\n\n# Early Stopping\ncallback = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\", patience=7)\n\nhistory = model.fit(training_data, training_target, epochs=25, validation_data=(validation_data, validation_target), callbacks=[callback])","metadata":{"execution":{"iopub.status.busy":"2023-03-05T02:28:20.429174Z","iopub.execute_input":"2023-03-05T02:28:20.429540Z","iopub.status.idle":"2023-03-05T02:47:19.420922Z","shell.execute_reply.started":"2023-03-05T02:28:20.429506Z","shell.execute_reply":"2023-03-05T02:47:19.419925Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"Epoch 1/25\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/backend.py:5677: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n  output, from_logits, \"Sigmoid\", \"binary_crossentropy\"\n","output_type":"stream"},{"name":"stdout","text":"1250/1250 [==============================] - ETA: 0s - loss: 6.1844 - accuracy: 0.9088","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/backend.py:5677: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n  output, from_logits, \"Sigmoid\", \"binary_crossentropy\"\n","output_type":"stream"},{"name":"stdout","text":"1250/1250 [==============================] - 64s 44ms/step - loss: 6.1844 - accuracy: 0.9088 - val_loss: 0.3019 - val_accuracy: 0.9459\nEpoch 2/25\n1250/1250 [==============================] - 45s 36ms/step - loss: 0.2551 - accuracy: 0.9551 - val_loss: 0.2366 - val_accuracy: 0.9546\nEpoch 3/25\n1250/1250 [==============================] - 45s 36ms/step - loss: 0.1877 - accuracy: 0.9676 - val_loss: 0.2077 - val_accuracy: 0.9576\nEpoch 4/25\n1250/1250 [==============================] - 44s 36ms/step - loss: 0.1466 - accuracy: 0.9763 - val_loss: 0.2014 - val_accuracy: 0.9538\nEpoch 5/25\n1250/1250 [==============================] - 46s 37ms/step - loss: 0.1197 - accuracy: 0.9806 - val_loss: 0.2397 - val_accuracy: 0.9553\nEpoch 6/25\n1250/1250 [==============================] - 45s 36ms/step - loss: 0.1006 - accuracy: 0.9864 - val_loss: 0.2138 - val_accuracy: 0.9542\nEpoch 7/25\n1250/1250 [==============================] - 45s 36ms/step - loss: 0.0861 - accuracy: 0.9886 - val_loss: 0.2445 - val_accuracy: 0.9535\nEpoch 8/25\n1250/1250 [==============================] - 45s 36ms/step - loss: 0.0794 - accuracy: 0.9896 - val_loss: 0.2448 - val_accuracy: 0.9540\nEpoch 9/25\n1250/1250 [==============================] - 44s 36ms/step - loss: 0.0705 - accuracy: 0.9916 - val_loss: 0.2084 - val_accuracy: 0.9511\nEpoch 10/25\n1250/1250 [==============================] - 47s 37ms/step - loss: 0.0641 - accuracy: 0.9923 - val_loss: 0.2669 - val_accuracy: 0.9534\nEpoch 11/25\n1250/1250 [==============================] - 44s 36ms/step - loss: 0.0626 - accuracy: 0.9925 - val_loss: 0.2438 - val_accuracy: 0.9533\nEpoch 12/25\n1250/1250 [==============================] - 45s 36ms/step - loss: 0.0590 - accuracy: 0.9930 - val_loss: 0.2412 - val_accuracy: 0.9515\nEpoch 13/25\n1250/1250 [==============================] - 46s 37ms/step - loss: 0.0534 - accuracy: 0.9943 - val_loss: 0.2668 - val_accuracy: 0.9403\nEpoch 14/25\n1250/1250 [==============================] - 47s 37ms/step - loss: 0.0545 - accuracy: 0.9939 - val_loss: 0.2492 - val_accuracy: 0.9501\nEpoch 15/25\n1250/1250 [==============================] - 44s 35ms/step - loss: 0.0526 - accuracy: 0.9940 - val_loss: 0.2637 - val_accuracy: 0.9454\nEpoch 16/25\n1250/1250 [==============================] - 44s 35ms/step - loss: 0.0527 - accuracy: 0.9943 - val_loss: 0.2424 - val_accuracy: 0.9516\nEpoch 17/25\n1250/1250 [==============================] - 45s 36ms/step - loss: 0.0502 - accuracy: 0.9941 - val_loss: 0.2448 - val_accuracy: 0.9524\nEpoch 18/25\n1250/1250 [==============================] - 45s 36ms/step - loss: 0.0476 - accuracy: 0.9951 - val_loss: 0.2208 - val_accuracy: 0.9505\nEpoch 19/25\n1250/1250 [==============================] - 45s 36ms/step - loss: 0.0468 - accuracy: 0.9954 - val_loss: 0.2636 - val_accuracy: 0.9539\nEpoch 20/25\n1250/1250 [==============================] - 44s 35ms/step - loss: 0.0442 - accuracy: 0.9955 - val_loss: 0.2661 - val_accuracy: 0.9479\nEpoch 21/25\n1250/1250 [==============================] - 44s 35ms/step - loss: 0.0480 - accuracy: 0.9941 - val_loss: 0.2728 - val_accuracy: 0.9506\nEpoch 22/25\n1250/1250 [==============================] - 44s 35ms/step - loss: 0.0430 - accuracy: 0.9959 - val_loss: 0.2361 - val_accuracy: 0.9534\nEpoch 23/25\n1250/1250 [==============================] - 44s 35ms/step - loss: 0.0421 - accuracy: 0.9953 - val_loss: 0.2959 - val_accuracy: 0.9553\nEpoch 24/25\n1250/1250 [==============================] - 44s 35ms/step - loss: 0.0425 - accuracy: 0.9956 - val_loss: 0.2611 - val_accuracy: 0.9551\nEpoch 25/25\n1250/1250 [==============================] - 44s 35ms/step - loss: 0.0410 - accuracy: 0.9958 - val_loss: 0.2711 - val_accuracy: 0.9536\n","output_type":"stream"}]},{"cell_type":"code","source":"# sample_text = \"\"\n# predictions = model.predict(np.array([sample_text]))\n# predictions[0]","metadata":{"execution":{"iopub.status.busy":"2023-03-04T01:06:55.562502Z","iopub.execute_input":"2023-03-04T01:06:55.563202Z","iopub.status.idle":"2023-03-04T01:06:55.589164Z","shell.execute_reply.started":"2023-03-04T01:06:55.563096Z","shell.execute_reply":"2023-03-04T01:06:55.588291Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-03-05T02:47:28.605833Z","iopub.execute_input":"2023-03-05T02:47:28.606221Z","iopub.status.idle":"2023-03-05T02:47:28.641364Z","shell.execute_reply.started":"2023-03-05T02:47:28.606182Z","shell.execute_reply":"2023-03-05T02:47:28.640609Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"Model: \"sequential_7\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n text_vectorization_4 (TextV  (None, None)             0         \n ectorization)                                                   \n                                                                 \n embedding_7 (Embedding)     (None, None, 512)         55971840  \n                                                                 \n conv1d_11 (Conv1D)          (None, None, 128)         327808    \n                                                                 \n max_pooling1d_11 (MaxPoolin  (None, None, 128)        0         \n g1D)                                                            \n                                                                 \n conv1d_12 (Conv1D)          (None, None, 64)          41024     \n                                                                 \n max_pooling1d_12 (MaxPoolin  (None, None, 64)         0         \n g1D)                                                            \n                                                                 \n bidirectional_14 (Bidirecti  (None, None, 256)        197632    \n onal)                                                           \n                                                                 \n bidirectional_15 (Bidirecti  (None, 128)              164352    \n onal)                                                           \n                                                                 \n dense_17 (Dense)            (None, 256)               33024     \n                                                                 \n dense_18 (Dense)            (None, 128)               32896     \n                                                                 \n dense_19 (Dense)            (None, 64)                8256      \n                                                                 \n dropout_7 (Dropout)         (None, 64)                0         \n                                                                 \n dense_20 (Dense)            (None, 1)                 65        \n                                                                 \n=================================================================\nTotal params: 56,776,897\nTrainable params: 56,776,897\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Getting test data","metadata":{}},{"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/toxic-message-classifier-dataset/test.csv\")\ntest_labels = pd.read_csv(\"/kaggle/input/toxic-message-classifier-dataset/test_labels.csv\")\n\ntest_labels = test_labels.loc[test_labels[\"toxic\"] >= 0]\nmerged_df = test_labels.merge(test_data, left_on=\"id\", right_on=\"id\")","metadata":{"execution":{"iopub.status.busy":"2023-03-05T02:47:34.697947Z","iopub.execute_input":"2023-03-05T02:47:34.698440Z","iopub.status.idle":"2023-03-05T02:47:35.851448Z","shell.execute_reply.started":"2023-03-05T02:47:34.698394Z","shell.execute_reply":"2023-03-05T02:47:35.850156Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"# Tests all rows with a value of 0 or 1\n\ntest_df = merged_df[[\"comment_text\", \"toxic\"]]\ntestTarget = test_df.pop(\"toxic\")\nmodel.evaluate(test_df, testTarget)","metadata":{"execution":{"iopub.status.busy":"2023-03-05T02:47:37.704553Z","iopub.execute_input":"2023-03-05T02:47:37.705157Z","iopub.status.idle":"2023-03-05T02:48:18.900729Z","shell.execute_reply.started":"2023-03-05T02:47:37.705107Z","shell.execute_reply":"2023-03-05T02:48:18.899710Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"2000/2000 [==============================] - 32s 16ms/step - loss: 0.3612 - accuracy: 0.9078\n","output_type":"stream"},{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"[0.3611910939216614, 0.9077651500701904]"},"metadata":{}}]},{"cell_type":"code","source":"# Tests only rows with a toxic value of 1\n\ntest_df = merged_df[[\"comment_text\", \"toxic\"]]\nnewTest_df = test_df.loc[test_df[\"toxic\"] == 1]\n\nnewTestTarget = newTest_df.pop(\"toxic\")\nmodel.evaluate(newTest_df, newTestTarget)","metadata":{"execution":{"iopub.status.busy":"2023-03-05T02:48:18.902649Z","iopub.execute_input":"2023-03-05T02:48:18.903526Z","iopub.status.idle":"2023-03-05T02:48:24.110775Z","shell.execute_reply.started":"2023-03-05T02:48:18.903484Z","shell.execute_reply":"2023-03-05T02:48:24.109502Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"191/191 [==============================] - 3s 16ms/step - loss: 1.1481 - accuracy: 0.7939\n","output_type":"stream"},{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"[1.148050308227539, 0.7939244508743286]"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}