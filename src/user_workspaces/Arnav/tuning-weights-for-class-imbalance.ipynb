{"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"ab65a6a126614c4d8a09c3bb162b3d2e4f4a949753c6f0f735c7c1fe269df83b"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Cleaning","metadata":{"id":"AYVsepnsN7Ys"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport tensorflow as tf\nfrom tensorflow import keras","metadata":{"execution":{"iopub.status.busy":"2023-03-11T01:06:02.330581Z","iopub.execute_input":"2023-03-11T01:06:02.331381Z","iopub.status.idle":"2023-03-11T01:06:14.338015Z","shell.execute_reply.started":"2023-03-11T01:06:02.331328Z","shell.execute_reply":"2023-03-11T01:06:14.336567Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/toxic-message-classifier-dataset/train_cleaned.csv')\ndata.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":250},"id":"T3ng90-PS0JD","outputId":"5bab9c74-8f9f-4c7d-d1b4-e034f7b7b3be","pycharm":{"is_executing":true},"execution":{"iopub.status.busy":"2023-03-11T01:06:15.797430Z","iopub.execute_input":"2023-03-11T01:06:15.798390Z","iopub.status.idle":"2023-03-11T01:06:18.970830Z","shell.execute_reply.started":"2023-03-11T01:06:15.798346Z","shell.execute_reply":"2023-03-11T01:06:18.969385Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                 id                                       comment_text  toxic  \\\n0  0000997932d777bf  explanation\\n  edits made   username hardcore ...      0   \n1  000103f0d9cfb60f  daww  matches  background colour im seemingly ...      0   \n2  000113f07ec002fd  hey man im really  trying  edit war     guy  c...      0   \n3  0001b41b1c6bb37e  cant make  real suggestions  improvement   won...      0   \n4  0001d958c54c6e35           sir   hero  chance  remember  page thats      0   \n\n   severe_toxic  obscene  threat  insult  identity_hate  \\\n0             0        0       0       0              0   \n1             0        0       0       0              0   \n2             0        0       0       0              0   \n3             0        0       0       0              0   \n4             0        0       0       0              0   \n\n                                  comment_text_words  \n0  ['explanation', 'edits', 'made', 'username', '...  \n1  ['daww', 'matches', 'background', 'colour', 'i...  \n2  ['hey', 'man', 'im', 'really', 'trying', 'edit...  \n3  ['cant', 'make', 'real', 'suggestions', 'impro...  \n4  ['sir', 'hero', 'chance', 'remember', 'page', ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n      <th>comment_text_words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>explanation\\n  edits made   username hardcore ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>['explanation', 'edits', 'made', 'username', '...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>daww  matches  background colour im seemingly ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>['daww', 'matches', 'background', 'colour', 'i...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>hey man im really  trying  edit war     guy  c...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>['hey', 'man', 'im', 'really', 'trying', 'edit...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>cant make  real suggestions  improvement   won...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>['cant', 'make', 'real', 'suggestions', 'impro...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>sir   hero  chance  remember  page thats</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>['sir', 'hero', 'chance', 'remember', 'page', ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Tokenizing Comments using TextVectorization","metadata":{}},{"cell_type":"code","source":"# finding the maximum number of words present in any given comment\nmaxlen = 0\nlongest_comment = \"\"\nfor comment in data['comment_text']:\n    length = len(comment)\n    if (length > maxlen):\n        longest_comment = comment\n    maxlen = max(maxlen, length)\n\nprint(\"Number of characters in the longest comment is\", maxlen)\nprint(\"Number of words in the longest comment is\",\n      len(longest_comment.split(\" \")) + 1)","metadata":{"execution":{"iopub.status.busy":"2023-03-11T01:06:18.977996Z","iopub.execute_input":"2023-03-11T01:06:18.981758Z","iopub.status.idle":"2023-03-11T01:06:19.192233Z","shell.execute_reply.started":"2023-03-11T01:06:18.981687Z","shell.execute_reply":"2023-03-11T01:06:19.190826Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Number of characters in the longest comment is 5000\nNumber of words in the longest comment is 456\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\n\nvectorize_layer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n\n    max_tokens=None,\n\n    # this is greater than the max words any comment has (774)\n    # the remaning spots in the output would be padded by 0s\n    output_sequence_length=800,\n\n    # converets to lowercase and skips all the punctuation\n    standardize=\"lower_and_strip_punctuation\",\n\n    # the tokens will be split at whitespaces\n    split=\"whitespace\",\n\n    # each of the tokens is represented as an integer\n    output_mode=\"int\",\n)","metadata":{"execution":{"iopub.status.busy":"2023-03-11T01:06:24.666648Z","iopub.execute_input":"2023-03-11T01:06:24.667077Z","iopub.status.idle":"2023-03-11T01:06:28.040175Z","shell.execute_reply.started":"2023-03-11T01:06:24.667040Z","shell.execute_reply":"2023-03-11T01:06:28.038847Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"numpyArray = data[data.columns[1]].to_numpy()\nvectorize_layer.adapt(numpyArray)","metadata":{"execution":{"iopub.status.busy":"2023-03-11T01:06:30.375512Z","iopub.execute_input":"2023-03-11T01:06:30.376385Z","iopub.status.idle":"2023-03-11T01:07:11.877152Z","shell.execute_reply.started":"2023-03-11T01:06:30.376331Z","shell.execute_reply":"2023-03-11T01:07:11.875718Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# testing\nvectorize_layer(\"hello, world!\")","metadata":{"execution":{"iopub.status.busy":"2023-03-11T01:07:11.880231Z","iopub.execute_input":"2023-03-11T01:07:11.881291Z","iopub.status.idle":"2023-03-11T01:07:12.080149Z","shell.execute_reply.started":"2023-03-11T01:07:11.881230Z","shell.execute_reply":"2023-03-11T01:07:12.078705Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(800,), dtype=int64, numpy=\narray([185, 161,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0])>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Creating a Tokenizer","metadata":{}},{"cell_type":"markdown","source":"### Gets all the words into one string","metadata":{}},{"cell_type":"code","source":"# Creates the tokenizer class\ntokenizer = keras.preprocessing.text.Tokenizer()\n\n# Combines all the words into one singular string\nallWordsString = \" \".join(data.head(50)[\"comment_text\"].tolist())\nallWordsList = allWordsString.split(r\"\\\\s+\")\n\n# Updates the tokenizer with the string of all words\ntokenizer.fit_on_texts(allWordsList)\n\n# Prints word dictionary\n# print(tokenizer.word_index)\n\n# Prints length of word dictionary\nprint(len(tokenizer.word_index))\n\n# Converts text to numbers\nprint(tokenizer.texts_to_sequences([\"page\", \"im\", \"use\", \"mussolini\"]))","metadata":{"execution":{"iopub.status.busy":"2023-03-11T01:07:12.165919Z","iopub.execute_input":"2023-03-11T01:07:12.166364Z","iopub.status.idle":"2023-03-11T01:07:12.190783Z","shell.execute_reply.started":"2023-03-11T01:07:12.166319Z","shell.execute_reply":"2023-03-11T01:07:12.188871Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"1077\n[[1], [2], [3], [1077]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Text Vectorization Layer\n### Following [https://www.tensorflow.org/text/tutorials/text_classification_rnn](http://)","metadata":{}},{"cell_type":"code","source":"NUM_ROWS = 10000\n\nMAX_LENGTH = None\nencoder = tf.keras.layers.TextVectorization(output_sequence_length=MAX_LENGTH)\nencoder.adapt(data.head(NUM_ROWS)[\"comment_text\"].tolist())\n\nvocab = np.array(encoder.get_vocabulary())\nvocab[:20]","metadata":{"execution":{"iopub.status.busy":"2023-03-11T01:07:41.588752Z","iopub.execute_input":"2023-03-11T01:07:41.589902Z","iopub.status.idle":"2023-03-11T01:07:43.558105Z","shell.execute_reply.started":"2023-03-11T01:07:41.589857Z","shell.execute_reply":"2023-03-11T01:07:43.556683Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"array(['', '[UNK]', 'article', 'page', 'wikipedia', 'would', 'talk',\n       'like', 'one', 'please', 'dont', 'see', 'also', 'im', 'know',\n       'think', 'edit', 'people', 'use', 'articles'], dtype='<U322')"},"metadata":{}}]},{"cell_type":"markdown","source":"### Testing the encoder\n\nEncoder removes punctuation and whitespace and forces lowercase so half the cleaning we did was useless","metadata":{}},{"cell_type":"code","source":"commentsToEncode = data.head(3)[\"comment_text\"]\nprint(commentsToEncode)\n\nencodedComments = encoder(commentsToEncode).numpy()\nprint(encodedComments)\n\nfor comment in encodedComments:\n    print(\" \".join(vocab[comment]))","metadata":{"execution":{"iopub.status.busy":"2023-03-11T01:07:45.791322Z","iopub.execute_input":"2023-03-11T01:07:45.791782Z","iopub.status.idle":"2023-03-11T01:07:45.823659Z","shell.execute_reply.started":"2023-03-11T01:07:45.791744Z","shell.execute_reply":"2023-03-11T01:07:45.822248Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"0    explanation\\n  edits made   username hardcore ...\n1    daww  matches  background colour im seemingly ...\n2    hey man im really  trying  edit war     guy  c...\nName: comment_text, dtype: object\n[[  530    53    41   437  4205 14587   257   208  2022  9650  6733  4903\n   2845    44  1016 11400  2690     9    10   157   357     6     3    56\n     13  3853]\n [35388  2050  1647  6725    13  3256  2365    26     6   977    95     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0]\n [  387   349    13    49   169    16   218   524  1606   406   367    30\n    399    53   270     6     3   126   341  2062   506   391     0     0\n      0     0]]\nexplanation edits made username hardcore metallica fan reverted werent vandalisms closure gas voted new york dolls fac please dont remove template talk page since im retired\ndaww matches background colour im seemingly stuck thanks talk january utc               \nhey man im really trying edit war guy constantly removing relevant information talking edits instead talk page seems care formatting actual info    \n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Building the model","metadata":{}},{"cell_type":"code","source":"# Sets random seed so results are identical every time\nSEED = 1\ntf.random.set_seed(SEED)\nnp.random.seed(SEED)\n\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nepochs = 5\nlearning_rate = 0.0001\noptimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\nembedding_size = 512\nlstm_size_1 = 128\nconv_size_2 = 64\n\nmodel = tf.keras.Sequential([\n    encoder,\n    tf.keras.layers.Embedding(\n        input_dim=len(encoder.get_vocabulary()),\n        output_dim=embedding_size,\n        mask_zero=True,\n        embeddings_regularizer=tf.keras.regularizers.L2(0.001)\n    ),\n    tf.keras.layers.Conv1D(128, 5, activation='relu', padding='same'),\n    tf.keras.layers.MaxPooling1D(pool_size=2),\n    tf.keras.layers.Conv1D(conv_size_2, 5, activation='relu', padding='same'),\n    tf.keras.layers.MaxPooling1D(pool_size=2),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_size_1, return_sequences=True)),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.001)),\n    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.001)),\n    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.001)),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizer,\n              metrics=['accuracy'])\n\n# Add early stopping callback to prevent overfitting\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3)\n\nmodel.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n             optimizer=tf.keras.optimizers.Adam(1e-4),\n              metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2023-03-11T01:07:48.878412Z","iopub.execute_input":"2023-03-11T01:07:48.878844Z","iopub.status.idle":"2023-03-11T01:07:50.979441Z","shell.execute_reply.started":"2023-03-11T01:07:48.878807Z","shell.execute_reply":"2023-03-11T01:07:50.978129Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"\n### Training the model","metadata":{}},{"cell_type":"code","source":"binaryDf = data.head(NUM_ROWS)[[\"comment_text\", \"toxic\"]]\n\nsplit_cutoff = int(0.8 * NUM_ROWS)\ntraining_data = binaryDf.iloc[:split_cutoff]\nvalidation_data = binaryDf.iloc[split_cutoff:]\n\ntraining_target = training_data.pop(\"toxic\")\nvalidation_target = validation_data.pop(\"toxic\")","metadata":{"execution":{"iopub.status.busy":"2023-03-11T01:07:55.467868Z","iopub.execute_input":"2023-03-11T01:07:55.469101Z","iopub.status.idle":"2023-03-11T01:07:55.483288Z","shell.execute_reply.started":"2023-03-11T01:07:55.469053Z","shell.execute_reply":"2023-03-11T01:07:55.481858Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Sample Weight = 2","metadata":{}},{"cell_type":"code","source":"sample_weight = np.ones(shape=(len(training_target),))\nsample_weight[training_target == 1] = 2.0\n\ncallback = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\", patience=7)\nhistory = model.fit(training_data, training_target, epochs=10, validation_data=(validation_data, validation_target), callbacks=[callback], sample_weight=sample_weight)","metadata":{"execution":{"iopub.status.busy":"2023-03-11T01:09:07.868121Z","iopub.execute_input":"2023-03-11T01:09:07.869772Z","iopub.status.idle":"2023-03-11T01:11:43.805677Z","shell.execute_reply.started":"2023-03-11T01:09:07.869673Z","shell.execute_reply":"2023-03-11T01:11:43.804309Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/backend.py:5677: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n  output, from_logits, \"Sigmoid\", \"binary_crossentropy\"\n","output_type":"stream"},{"name":"stdout","text":"249/250 [============================>.] - ETA: 0s - loss: 9.5216 - accuracy: 0.9032","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/backend.py:5677: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n  output, from_logits, \"Sigmoid\", \"binary_crossentropy\"\n","output_type":"stream"},{"name":"stdout","text":"250/250 [==============================] - 52s 123ms/step - loss: 9.5010 - accuracy: 0.9030 - val_loss: 3.9764 - val_accuracy: 0.9120\nEpoch 2/10\n250/250 [==============================] - 11s 45ms/step - loss: 2.3008 - accuracy: 0.9043 - val_loss: 1.0307 - val_accuracy: 0.9120\nEpoch 3/10\n250/250 [==============================] - 10s 39ms/step - loss: 0.8538 - accuracy: 0.9061 - val_loss: 0.4802 - val_accuracy: 0.9290\nEpoch 4/10\n250/250 [==============================] - 10s 39ms/step - loss: 0.4595 - accuracy: 0.9391 - val_loss: 0.3721 - val_accuracy: 0.9445\nEpoch 5/10\n250/250 [==============================] - 9s 35ms/step - loss: 0.2890 - accuracy: 0.9796 - val_loss: 0.3662 - val_accuracy: 0.9370\nEpoch 6/10\n250/250 [==============================] - 9s 38ms/step - loss: 0.2092 - accuracy: 0.9921 - val_loss: 0.4043 - val_accuracy: 0.9265\nEpoch 7/10\n250/250 [==============================] - 10s 40ms/step - loss: 0.1717 - accuracy: 0.9961 - val_loss: 0.5494 - val_accuracy: 0.9070\nEpoch 8/10\n250/250 [==============================] - 9s 35ms/step - loss: 0.1505 - accuracy: 0.9969 - val_loss: 0.4746 - val_accuracy: 0.9445\nEpoch 9/10\n250/250 [==============================] - 9s 36ms/step - loss: 0.1416 - accuracy: 0.9964 - val_loss: 0.4721 - val_accuracy: 0.9455\nEpoch 10/10\n250/250 [==============================] - 9s 38ms/step - loss: 0.1386 - accuracy: 0.9958 - val_loss: 0.4431 - val_accuracy: 0.9365\n","output_type":"stream"}]},{"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/toxic-message-classifier-dataset/test.csv\")\ntest_labels = pd.read_csv(\"/kaggle/input/toxic-message-classifier-dataset/test_labels.csv\")\n\ntest_labels = test_labels.loc[test_labels[\"toxic\"] >= 0]\nmerged_df = test_labels.merge(test_data, left_on=\"id\", right_on=\"id\")","metadata":{"execution":{"iopub.status.busy":"2023-03-11T01:11:59.173272Z","iopub.execute_input":"2023-03-11T01:11:59.173858Z","iopub.status.idle":"2023-03-11T01:12:01.979985Z","shell.execute_reply.started":"2023-03-11T01:11:59.173794Z","shell.execute_reply":"2023-03-11T01:12:01.978709Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Tests all rows with a value of 0 or 1\n\ntest_df = merged_df[[\"comment_text\", \"toxic\"]]\ntestTarget = test_df.pop(\"toxic\")\nmodel.evaluate(test_df, testTarget)","metadata":{"execution":{"iopub.status.busy":"2023-03-11T01:12:05.076483Z","iopub.execute_input":"2023-03-11T01:12:05.078403Z","iopub.status.idle":"2023-03-11T01:12:53.193898Z","shell.execute_reply.started":"2023-03-11T01:12:05.078308Z","shell.execute_reply":"2023-03-11T01:12:53.192053Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"2000/2000 [==============================] - 48s 24ms/step - loss: 0.8526 - accuracy: 0.8040\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"[0.8525853753089905, 0.8039951324462891]"},"metadata":{}}]}]}