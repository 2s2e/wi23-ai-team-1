{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom nltk.corpus import stopwords\n\nimport nltk\nnltk.download(\"stopwords\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-04T07:19:33.243735Z","iopub.execute_input":"2023-03-04T07:19:33.244217Z","iopub.status.idle":"2023-03-04T07:19:33.254234Z","shell.execute_reply.started":"2023-03-04T07:19:33.244166Z","shell.execute_reply":"2023-03-04T07:19:33.252869Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"def filterByNumWords(df: pd.DataFrame, numWords: int) -> pd.DataFrame:\n    \"\"\"\n    Filter out comments that have fewer words than numWords\n\n    :param df: dataframe\n    :param numWords: int\n    :return: dataframe with comments with fewer words than numWords filtered out\n    \"\"\"\n\n    if \"comment_text_words\" not in df.columns:\n        df = splitIntoWords(df)\n\n    return df.loc[df[\"comment_text_words\"].str.len() > numWords]\n\n\ndef filterNonEnglishChars(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n        Filter out non-english characters\n\n        :param df: dataframe\n        :return: dataframe with non-english characters filtered out\n    \"\"\"\n\n    # df[\"comment_text\"] = df['comment_text'].str \\\n    #     .encode('ascii', 'ignore').str.decode('ascii')\n    df[\"comment_text\"].replace(r\"[^A-Za-z\\s]+\", \"\", regex=True,\n                               inplace=True)\n\n    return df\n\n\ndef removeStopWords(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Remove stop words\n\n    :param df: dataframe\n    :return: dataframe with stop words removed\n    \"\"\"\n\n    wordsToRemove = stopwords.words('english')\n    pattern = r\"\\b({})\\b\".format('|'.join(wordsToRemove))\n    df[\"comment_text\"] = df[\"comment_text\"].str.replace(\n        pattern, \"\", regex=True)\n\n    return df\n\n\ndef toLowerCase(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Forces all characters to be lowercase\n\n    :param df: dataframe\n    :return: dataframe with all characters forced to be lowercase\n    \"\"\"\n\n    df[\"comment_text\"] = df[\"comment_text\"].str.lower()\n\n    return df\n\n\ndef splitIntoWords(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Split comments into words and forces them to be lowercase\n\n    :param df: dataframe\n    :return: dataframe with comments split into words\n    \"\"\"\n\n    df[\"comment_text_words\"] = df[\"comment_text\"].str.split(\"\\\\s+\")\n\n    return df\n\n\ndef isEnglish(s: str) -> bool:\n    \"\"\"\n    Check if a string contains all english characters\n\n    :param s: string to check\n    :return: whether string contains only english characters\n    \"\"\"\n\n    try:\n        s.encode(encoding='utf-8').decode('ascii')\n    except UnicodeDecodeError:\n        return False\n    else:\n        return True\n\n\ndef trimWhitespace(df: pd.DataFrame) -> pd.DataFrame:\n    df[\"comment_text\"] = df[\"comment_text\"].str.strip()\n\n    return df\n","metadata":{"execution":{"iopub.status.busy":"2023-03-04T07:19:34.479494Z","iopub.execute_input":"2023-03-04T07:19:34.479951Z","iopub.status.idle":"2023-03-04T07:19:34.493988Z","shell.execute_reply.started":"2023-03-04T07:19:34.479910Z","shell.execute_reply":"2023-03-04T07:19:34.492607Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def cleanData():\n    df = pd.read_csv(\"/kaggle/input/toxic-message-classifier-dataset/train.csv\")\n    df = toLowerCase(df)\n    df = filterNonEnglishChars(df)\n    df = removeStopWords(df)\n    df = trimWhitespace(df)\n    df = splitIntoWords(df)\n    df = filterByNumWords(df, 3)\n\n    df.to_csv(\"train_cleaned.csv\", index=False)\n\n\ncleanData()","metadata":{"execution":{"iopub.status.busy":"2023-03-04T07:19:35.910691Z","iopub.execute_input":"2023-03-04T07:19:35.911569Z","iopub.status.idle":"2023-03-04T07:19:59.803451Z","shell.execute_reply.started":"2023-03-04T07:19:35.911523Z","shell.execute_reply":"2023-03-04T07:19:59.801788Z"},"trusted":true},"execution_count":6,"outputs":[]}]}